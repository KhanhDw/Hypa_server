import requests
from bs4 import BeautifulSoup
import json
import re
from urllib.parse import urlparse, unquote
from typing import Dict, Optional, List, Any
import logging
import time

# Selenium imports
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options as ChromeOptions
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class FacebookContentExtractor:
    """Service Ä‘á»ƒ láº¥y FULL ná»™i dung tá»« URL Facebook (khÃ´ng chá»‰ metadata)"""

    def __init__(self, use_selenium: bool = True, headless: bool = True):
        """
        Args:
            use_selenium: LuÃ´n dÃ¹ng Selenium Ä‘á»ƒ láº¥y full content
            headless: Cháº¡y Chrome á»Ÿ cháº¿ Ä‘á»™ headless
        """
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9,vi;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        self.use_selenium = use_selenium
        self.headless = headless
        self.driver = None
        self.session = requests.Session()
        self.session.headers.update(self.headers)

    def init_selenium_driver(self):
        """Khá»Ÿi táº¡o Selenium WebDriver vá»›i cáº¥u hÃ¬nh tá»‘i Æ°u cho Facebook"""
        try:
            chrome_options = ChromeOptions()

            if self.headless:
                chrome_options.add_argument('--headless=new')

            # Cáº¥u hÃ¬nh Ä‘á»ƒ trÃ¡nh bá»‹ phÃ¡t hiá»‡n lÃ  bot
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)

            # User agent vÃ  cÃ¡c headers
            chrome_options.add_argument(f'user-agent={self.headers["User-Agent"]}')
            chrome_options.add_argument('--disable-web-security')
            chrome_options.add_argument('--allow-running-insecure-content')
            chrome_options.add_argument('--disable-notifications')
            chrome_options.add_argument('--disable-popup-blocking')
            chrome_options.add_argument('--disable-infobars')

            # Táº¯t cÃ¡c tÃ­nh nÄƒng khÃ´ng cáº§n thiáº¿t
            chrome_options.add_argument('--disable-background-timer-throttling')
            chrome_options.add_argument('--disable-backgrounding-occluded-windows')
            chrome_options.add_argument('--disable-renderer-backgrounding')

            # Táº£i áº£nh (cÃ³ thá»ƒ táº¯t Ä‘á»ƒ tÄƒng tá»‘c)
            prefs = {
                'profile.default_content_setting_values': {
                    'images': 2,  # 1=Allow, 2=Block
                    'javascript': 1,
                    'plugins': 2,
                    'popups': 2,
                    'geolocation': 2,
                    'notifications': 2,
                    'auto_select_certificate': 2,
                    'fullscreen': 2,
                    'mouselock': 2,
                    'mixed_script': 2,
                    'media_stream': 2,
                    'media_stream_mic': 2,
                    'media_stream_camera': 2,
                    'protocol_handlers': 2,
                    'ppapi_broker': 2,
                    'automatic_downloads': 2,
                    'midi_sysex': 2,
                    'push_messaging': 2,
                    'ssl_cert_decisions': 2,
                    'metro_switch_to_desktop': 2,
                    'protected_media_identifier': 2,
                    'app_banner': 2,
                    'site_engagement': 2,
                    'durable_storage': 2
                }
            }
            chrome_options.add_experimental_option('prefs', prefs)

            # Tá»± Ä‘á»™ng quáº£n lÃ½ ChromeDriver
            service = ChromeService(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)

            # áº¨n automation
            self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                'source': '''
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5]
                    });
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['en-US', 'en', 'vi']
                    });
                '''
            })

            return True
        except Exception as e:
            logger.error(f"KhÃ´ng thá»ƒ khá»Ÿi táº¡o Selenium driver: {e}")
            return False

    def close_selenium_driver(self):
        """ÄÃ³ng Selenium WebDriver"""
        if self.driver:
            try:
                self.driver.quit()
                self.driver = None
            except:
                pass

    def extract_full_content_selenium(self, url: str, timeout: int = 40) -> Dict:
        """
        Láº¥y FULL ná»™i dung tá»« Facebook báº±ng Selenium

        Returns:
            Dict chá»©a full content vÃ  metadata
        """
        if not self.driver:
            if not self.init_selenium_driver():
                return {}

        result = {
            'full_title': '',
            'full_description': '',
            'full_text': '',
            'post_content': '',
            'author_name': '',
            'author_url': '',
            'post_time': '',
            'reactions_count': '',
            'comments_count': '',
            'shares_count': '',
            'hashtags': [],
            'mentions': [],
            'links': []
        }

        try:
            logger.info(f"Äang truy cáº­p vá»›i Selenium: {url}")
            self.driver.get(url)

            # Chá» trang load
            time.sleep(5)

            # Cá»‘ gáº¯ng Ä‘Äƒng nháº­p náº¿u cáº§n (Ä‘á»ƒ xem ná»™i dung private)
            # self._try_login_if_needed()

            # Cuá»™n trang Ä‘á»ƒ load ná»™i dung
            self._scroll_page()

            # Äá»£i ná»™i dung xuáº¥t hiá»‡n
            time.sleep(3)

            # PhÃ¢n tÃ­ch loáº¡i post
            post_type = self._detect_post_type()

            # Láº¥y full content dá»±a trÃªn loáº¡i post
            if post_type == 'video':
                content = self._extract_video_content()
            elif post_type == 'photo':
                content = self._extract_photo_content()
            elif post_type == 'text':
                content = self._extract_text_content()
            elif post_type == 'share':
                content = self._extract_share_content()
            else:
                content = self._extract_general_content()

            # Gá»™p káº¿t quáº£
            result.update(content)

            # Láº¥y thÃªm metadata tá»« HTML
            html_content = self.driver.page_source
            metadata = self._extract_metadata_from_html(html_content)

            # Káº¿t há»£p metadata
            result.update(metadata)

            # LÃ m sáº¡ch ná»™i dung
            result = self._clean_content(result)

        except Exception as e:
            logger.error(f"Lá»—i khi extract content: {e}")

        return result

    def _scroll_page(self):
        """Cuá»™n trang Ä‘á»ƒ load ná»™i dung"""
        try:
            # Cuá»™n tá»« tá»«
            for i in range(3):
                scroll_amount = 500 * (i + 1)
                self.driver.execute_script(f"window.scrollTo(0, {scroll_amount})")
                time.sleep(1)

            # Cuá»™n lÃªn Ä‘áº§u trang
            self.driver.execute_script("window.scrollTo(0, 0)")
            time.sleep(1)
        except:
            pass

    def _detect_post_type(self) -> str:
        """PhÃ¡t hiá»‡n loáº¡i post Facebook"""
        try:
            page_source = self.driver.page_source.lower()

            # Kiá»ƒm tra cÃ¡c selector Ä‘áº·c trÆ°ng
            if 'video' in page_source and any(x in page_source for x in ['videoplayer', 'video player', 'fbwatch']):
                return 'video'
            elif 'photo' in page_source and any(x in page_source for x in ['photo-container', 'photo_', '/photo/']):
                return 'photo'
            elif 'shared a post' in page_source or 'shared a memory' in page_source:
                return 'share'
            elif 'status' in page_source or 'post' in page_source:
                return 'text'
            else:
                return 'general'
        except:
            return 'general'

    def _extract_video_content(self) -> Dict:
        """TrÃ­ch xuáº¥t ná»™i dung video post"""
        content = {}

        try:
            # Thá»­ tÃ¬m tiÃªu Ä‘á» video
            selectors = [
                'div[data-testid="story_header"] h2',
                'div[role="article"] h2',
                'div[data-ad-preview="message"]',
                'div[class*="userContent"]',
                'div[data-testid="post_message"]',
                'div[class*="postContent"]'
            ]

            for selector in selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text:
                        content['full_title'] = element.text.strip()
                        break
                except:
                    continue

            # Thá»­ tÃ¬m mÃ´ táº£ video
            desc_selectors = [
                'div[class*="videoDescription"]',
                'div[data-testid="videoDescription"]',
                'div[class*="captionText"]',
                'div[class*="descriptionText"]'
            ]

            for selector in desc_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text and not content.get('full_description'):
                        content['full_description'] = element.text.strip()
                except:
                    continue

            # Náº¿u khÃ´ng tÃ¬m tháº¥y mÃ´ táº£ riÃªng, sá»­ dá»¥ng tiÃªu Ä‘á»
            if not content.get('full_description') and content.get('full_title'):
                content['full_description'] = content['full_title']

            # Láº¥y tÃªn tÃ¡c giáº£
            author_selectors = [
                'a[role="link"][aria-label*="Facebook"]',
                'a[href*="/facebook.com/"]',
                'div[data-testid="story_header"] a',
                'h2 a'
            ]

            for selector in author_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text:
                        content['author_name'] = element.text.strip()
                        content['author_url'] = element.get_attribute('href')
                        break
                except:
                    continue

            # Láº¥y thá»i gian Ä‘Äƒng
            time_selectors = [
                'span[data-testid="story_timestamp"]',
                'a[aria-label*="Posted"]',
                'abbr[data-utime]',
                'a[class*="timestamp"]'
            ]

            for selector in time_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text:
                        content['post_time'] = element.text.strip()
                        break
                except:
                    continue

            # Láº¥y sá»‘ lÆ°á»£ng reaction, comment, share
            self._extract_post_stats(content)

        except Exception as e:
            logger.warning(f"KhÃ´ng thá»ƒ extract video content: {e}")

        return content

    def _extract_photo_content(self) -> Dict:
        """TrÃ­ch xuáº¥t ná»™i dung photo post"""
        content = {}

        try:
            # TÃ¬m caption áº£nh
            caption_selectors = [
                'div[data-testid="post_message"]',
                'div[class*="userContent"]',
                'div[data-ad-preview="message"]',
                'div[class*="caption"]',
                'div[role="article"] div[dir="auto"]'
            ]

            for selector in caption_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        if element.text and len(element.text.strip()) > 10:
                            content['full_description'] = element.text.strip()
                            content['full_title'] = element.text[:100] + '...' if len(element.text) > 100 else element.text
                            break
                    if content.get('full_description'):
                        break
                except:
                    continue

            # Láº¥y tÃªn tÃ¡c giáº£
            self._extract_author_info(content)

            # Láº¥y thá»i gian
            self._extract_post_time(content)

            # Láº¥y stats
            self._extract_post_stats(content)

        except Exception as e:
            logger.warning(f"KhÃ´ng thá»ƒ extract photo content: {e}")

        return content

    def _extract_text_content(self) -> Dict:
        """TrÃ­ch xuáº¥t ná»™i dung text post"""
        content = {}

        try:
            # TÃ¬m ná»™i dung bÃ i post
            content_selectors = [
                'div[data-testid="post_message"]',
                'div[class*="userContent"]',
                'div[data-ad-preview="message"]',
                'div[role="article"]',
                'div[dir="auto"][class*="text"]'
            ]

            for selector in content_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text:
                        full_text = element.text.strip()
                        content['full_text'] = full_text

                        # TÃ¡ch thÃ nh title vÃ  description
                        lines = full_text.split('\n')
                        if lines:
                            content['full_title'] = lines[0][:200]
                            if len(lines) > 1:
                                content['full_description'] = '\n'.join(lines[1:])[:500]
                            else:
                                content['full_description'] = lines[0][:500]
                        break
                except:
                    continue

            # Láº¥y author vÃ  time
            self._extract_author_info(content)
            self._extract_post_time(content)
            self._extract_post_stats(content)

            # TrÃ­ch xuáº¥t hashtag vÃ  mentions
            self._extract_tags_and_mentions(content)

        except Exception as e:
            logger.warning(f"KhÃ´ng thá»ƒ extract text content: {e}")

        return content

    def _extract_share_content(self) -> Dict:
        """TrÃ­ch xuáº¥t ná»™i dung share post"""
        content = {}

        try:
            # TÃ¬m ná»™i dung share
            share_selectors = [
                'div[data-testid="story_message"]',
                'div[class*="shared_content"]',
                'div[role="article"] div[dir="auto"]'
            ]

            for selector in share_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text:
                        content['full_text'] = element.text.strip()
                        break
                except:
                    continue

            # TÃ¬m ná»™i dung gá»‘c Ä‘Æ°á»£c share
            original_selectors = [
                'div[data-testid="shared_story"]',
                'div[class*="shared_post"]',
                'div[data-ft*="original_content"]'
            ]

            for selector in original_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text:
                        content['shared_content'] = element.text.strip()
                        break
                except:
                    continue

            self._extract_author_info(content)
            self._extract_post_time(content)
            self._extract_post_stats(content)

        except Exception as e:
            logger.warning(f"KhÃ´ng thá»ƒ extract share content: {e}")

        return content

    def _extract_general_content(self) -> Dict:
        """TrÃ­ch xuáº¥t ná»™i dung tá»•ng quÃ¡t"""
        content = {}

        try:
            # Thá»­ tÃ¬m táº¥t cáº£ ná»™i dung text quan trá»ng
            all_text_elements = self.driver.find_elements(By.CSS_SELECTOR,
                'div[role="article"], div[data-testid*="post"], div[class*="content"]')

            texts = []
            for element in all_text_elements:
                if element.text and len(element.text.strip()) > 20:
                    texts.append(element.text.strip())

            if texts:
                content['full_text'] = '\n\n'.join(texts)

                # Táº¡o title vÃ  description tá»« ná»™i dung
                first_text = texts[0]
                if len(first_text) > 100:
                    content['full_title'] = first_text[:100] + '...'
                    content['full_description'] = first_text[:500] + '...' if len(first_text) > 500 else first_text
                else:
                    content['full_title'] = first_text
                    content['full_description'] = first_text

            self._extract_author_info(content)
            self._extract_post_time(content)

        except Exception as e:
            logger.warning(f"KhÃ´ng thá»ƒ extract general content: {e}")

        return content

    def _extract_author_info(self, content: Dict):
        """TrÃ­ch xuáº¥t thÃ´ng tin tÃ¡c giáº£"""
        try:
            author_selectors = [
                'a[role="link"][aria-label*="Facebook"]',
                'a[href*="/facebook.com/"]',
                'div[data-testid="story_header"] a',
                'h2 a',
                'a[class*="actor"]'
            ]

            for selector in author_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text and not content.get('author_name'):
                        content['author_name'] = element.text.strip()
                        content['author_url'] = element.get_attribute('href')
                        break
                except:
                    continue
        except:
            pass

    def _extract_post_time(self, content: Dict):
        """TrÃ­ch xuáº¥t thá»i gian Ä‘Äƒng"""
        try:
            time_selectors = [
                'span[data-testid="story_timestamp"]',
                'a[aria-label*="Posted"]',
                'abbr[data-utime]',
                'a[class*="timestamp"]',
                'span[class*="timestamp"]'
            ]

            for selector in time_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text and not content.get('post_time'):
                        content['post_time'] = element.text.strip()
                        break
                except:
                    continue
        except:
            pass

    def _extract_post_stats(self, content: Dict):
        """TrÃ­ch xuáº¥t sá»‘ lÆ°á»£ng reactions, comments, shares"""
        try:
            # Reactions
            reaction_selectors = [
                'span[data-testid="UFI2ReactionsCount"]',
                'span[class*="reactionsCount"]',
                'a[aria-label*="reaction"]',
                'div[aria-label*="reaction"]'
            ]

            for selector in reaction_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text:
                        content['reactions_count'] = element.text.strip()
                        break
                except:
                    continue

            # Comments
            comment_selectors = [
                'span[data-testid="UFI2CommentsCount"]',
                'a[aria-label*="comment"]',
                'span[class*="comment"]'
            ]

            for selector in comment_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text:
                        content['comments_count'] = element.text.strip()
                        break
                except:
                    continue

            # Shares
            share_selectors = [
                'span[data-testid="UFI2SharesCount"]',
                'a[aria-label*="share"]',
                'span[class*="share"]'
            ]

            for selector in share_selectors:
                try:
                    element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if element.text:
                        content['shares_count'] = element.text.strip()
                        break
                except:
                    continue
        except:
            pass

    def _extract_tags_and_mentions(self, content: Dict):
        """TrÃ­ch xuáº¥t hashtag vÃ  mentions"""
        try:
            if content.get('full_text'):
                text = content['full_text']

                # Hashtags
                hashtags = re.findall(r'#(\w+)', text)
                if hashtags:
                    content['hashtags'] = hashtags

                # Mentions (@username)
                mentions = re.findall(r'@(\w+)', text)
                if mentions:
                    content['mentions'] = mentions

                # Links
                links = re.findall(r'https?://\S+', text)
                if links:
                    content['links'] = links
        except:
            pass

    def _extract_metadata_from_html(self, html_content: str) -> Dict:
        """TrÃ­ch xuáº¥t metadata tá»« HTML (bá»• sung)"""
        soup = BeautifulSoup(html_content, 'html.parser')
        metadata = {}

        try:
            # TÃ¬m tháº» title
            title_tag = soup.find('title')
            if title_tag and title_tag.text:
                metadata['page_title'] = title_tag.text.strip()

            # TÃ¬m meta description
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            if meta_desc and meta_desc.get('content'):
                metadata['meta_description'] = meta_desc['content']

            # TÃ¬m táº¥t cáº£ text cÃ³ thá»ƒ lÃ  ná»™i dung
            potential_content = []

            # CÃ¡c selector cÃ³ thá»ƒ chá»©a ná»™i dung
            content_selectors = [
                'div[data-testid="post_message"]',
                'div[class*="userContent"]',
                'div[role="article"]',
                'div[dir="auto"]',
                'p',
                'span',
                'div'
            ]

            for selector in content_selectors:
                elements = soup.select(selector)
                for element in elements:
                    text = element.get_text(strip=True)
                    if text and len(text) > 50 and text not in potential_content:
                        potential_content.append(text)

            if potential_content:
                # Sáº¯p xáº¿p theo Ä‘á»™ dÃ i (thÆ°á»ng ná»™i dung dÃ i nháº¥t lÃ  ná»™i dung chÃ­nh)
                potential_content.sort(key=len, reverse=True)
                metadata['potential_contents'] = potential_content[:3]  # Láº¥y 3 ná»™i dung dÃ i nháº¥t

        except Exception as e:
            logger.warning(f"KhÃ´ng thá»ƒ extract metadata tá»« HTML: {e}")

        return metadata

    def _clean_content(self, content: Dict) -> Dict:
        """LÃ m sáº¡ch vÃ  chuáº©n hÃ³a ná»™i dung"""
        cleaned = content.copy()

        # Loáº¡i bá» cÃ¡c trÆ°á»ng rá»—ng
        for key in list(cleaned.keys()):
            if isinstance(cleaned[key], str) and not cleaned[key].strip():
                cleaned[key] = ''
            elif isinstance(cleaned[key], list) and not cleaned[key]:
                cleaned[key] = []

        # Giá»›i háº¡n Ä‘á»™ dÃ i
        if cleaned.get('full_title') and len(cleaned['full_title']) > 200:
            cleaned['full_title'] = cleaned['full_title'][:197] + '...'

        if cleaned.get('full_description') and len(cleaned['full_description']) > 1000:
            cleaned['full_description'] = cleaned['full_description'][:997] + '...'

        if cleaned.get('full_text') and len(cleaned['full_text']) > 5000:
            cleaned['full_text'] = cleaned['full_text'][:4997] + '...'

        return cleaned

    def get_full_content(self, url: str, timeout: int = 40) -> Dict:
        """
        Láº¥y FULL ná»™i dung tá»« URL Facebook

        Returns:
            Dict chá»©a full content vÃ  metadata
        """
        result = {
            'success': False,
            'error': None,
            'url': url,
            'content': {},
            'metadata': {},
            'method': 'selenium'
        }

        try:
            # LuÃ´n dÃ¹ng Selenium Ä‘á»ƒ láº¥y full content
            if not self.use_selenium:
                logger.warning("Selenium Ä‘Æ°á»£c khuyáº¿n nghá»‹ Ä‘á»ƒ láº¥y full content")

            # Láº¥y full content báº±ng Selenium
            full_content = self.extract_full_content_selenium(url, timeout)

            # Láº¥y thÃªm metadata OG (dÃ¹ng requests cho nhanh)
            try:
                response = self.session.get(url, timeout=10)
                if response.status_code == 200:
                    metadata = self._extract_og_metadata(response.text)
                    result['metadata'] = metadata
            except:
                pass

            # Gá»™p káº¿t quáº£
            result['content'] = full_content

            # Kiá»ƒm tra xem cÃ³ láº¥y Ä‘Æ°á»£c ná»™i dung khÃ´ng
            if any([full_content.get('full_title'),
                    full_content.get('full_description'),
                    full_content.get('full_text')]):
                result['success'] = True
            else:
                result['error'] = 'KhÃ´ng tÃ¬m tháº¥y ná»™i dung'
                result['success'] = False

        except Exception as e:
            result['error'] = f"Lá»—i: {str(e)}"
            logger.error(f"Lá»—i khi láº¥y full content: {e}")

        return result

    def _extract_og_metadata(self, html_content: str) -> Dict:
        """TrÃ­ch xuáº¥t OG metadata cÆ¡ báº£n"""
        soup = BeautifulSoup(html_content, 'html.parser')
        metadata = {}

        # Láº¥y OG metadata
        og_tags = soup.find_all('meta', property=lambda x: x and x.startswith('og:'))
        for tag in og_tags:
            prop = tag.get('property', '').replace('og:', '')
            content = tag.get('content', '')
            if content:
                metadata[prop] = content

        return metadata

    def cleanup(self):
        """Dá»n dáº¹p tÃ i nguyÃªn"""
        self.close_selenium_driver()
        self.session.close()


# Sá»­ dá»¥ng
if __name__ == "__main__":
    # Khá»Ÿi táº¡o extractor
    extractor = FacebookContentExtractor(use_selenium=True, headless=True)

    test_urls = [
        "https://www.facebook.com/share/p/19FTEP281g/",
        "https://www.facebook.com/photo/?fbid=122116530465046735&set=gm.1482479739506865&idorvanity=440881430333373",
        "https://www.facebook.com/reel/703809526002594",
        # ThÃªm cÃ¡c URL khÃ¡c Ä‘á»ƒ test
    ]

    try:
        for url in test_urls:
            print(f"\n{'='*80}")
            print(f"ğŸ“± Äang phÃ¢n tÃ­ch: {url}")
            print(f"{'='*80}")

            result = extractor.get_full_content(url, timeout=40)

            if result['success']:
                content = result['content']
                metadata = result['metadata']

                print("âœ… Láº¥y thÃ nh cÃ´ng FULL CONTENT!")

                # Hiá»ƒn thá»‹ full content
                if content.get('full_title'):
                    print(f"\nğŸ“Œ FULL TITLE: {content['full_title']}")

                if content.get('full_description'):
                    print(f"\nğŸ“ FULL DESCRIPTION: {content['full_description']}")

                if content.get('full_text'):
                    print(f"\nğŸ“„ FULL TEXT ({len(content['full_text'])} chars):")
                    print(f"{content['full_text'][:500]}..." if len(content['full_text']) > 500 else content['full_text'])

                if content.get('author_name'):
                    print(f"\nğŸ‘¤ TÃ¡c giáº£: {content['author_name']}")

                if content.get('post_time'):
                    print(f"â° Thá»i gian: {content['post_time']}")

                # Hiá»ƒn thá»‹ stats
                if any([content.get('reactions_count'),
                        content.get('comments_count'),
                        content.get('shares_count')]):
                    print(f"\nğŸ“Š Thá»‘ng kÃª:")
                    if content.get('reactions_count'):
                        print(f"  â¤ï¸  Reactions: {content['reactions_count']}")
                    if content.get('comments_count'):
                        print(f"  ğŸ’¬ Comments: {content['comments_count']}")
                    if content.get('shares_count'):
                        print(f"  ğŸ”„ Shares: {content['shares_count']}")

                # Hiá»ƒn thá»‹ metadata OG (Ä‘á»ƒ so sÃ¡nh)
                if metadata:
                    print(f"\nğŸ” OG Metadata (bá»‹ cáº¯t xÃ©n):")
                    if metadata.get('title'):
                        print(f"  Title: {metadata['title']}")
                    if metadata.get('description'):
                        print(f"  Description: {metadata['description'][:100]}...")

                # So sÃ¡nh Ä‘á»™ dÃ i
                if content.get('full_description') and metadata.get('description'):
                    og_len = len(metadata['description'])
                    full_len = len(content['full_description'])
                    print(f"\nğŸ“ So sÃ¡nh: OG Description: {og_len} chars | Full Description: {full_len} chars")
                    print(f"   ChÃªnh lá»‡ch: {full_len - og_len} chars")

            else:
                print(f"âŒ Tháº¥t báº¡i: {result.get('error', 'Unknown error')}")

            print(f"\nâ³ Äá»£i 3 giÃ¢y trÆ°á»›c khi xá»­ lÃ½ URL tiáº¿p theo...")
            time.sleep(3)

    finally:
        extractor.cleanup()
        print("\nâœ¨ HoÃ n thÃ nh!")